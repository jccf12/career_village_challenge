{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_LDA_Text_Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNoh4Auhi4TJ"
      },
      "source": [
        "##Clone Repo to get data and preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XmUzx-oMx3H"
      },
      "source": [
        "! git clone https://github.com/jccf12/career_village_challenge.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwV-77wywbKk"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import random\n",
        "random.seed(30)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxhZoC8WwbKk"
      },
      "source": [
        "#Read data files\n",
        "\n",
        "answers = pd.read_csv(\"career_village_challenge/data/answers.csv\")\n",
        "answers_scores = pd.read_csv(\"career_village_challenge/data/answer_scores.csv\")\n",
        "\n",
        "\n",
        "emails1 = pd.read_csv(\"career_village_challenge/data/emails1.csv\")\n",
        "emails2 = pd.read_csv(\"career_village_challenge/data/emails2.csv\")\n",
        "emails = pd.concat([emails1,emails2])\n",
        "\n",
        "group_members = pd.read_csv(\"career_village_challenge/data/group_memberships.csv\")\n",
        "groups = pd.read_csv(\"career_village_challenge/data/groups.csv\")\n",
        "\n",
        "matches1 = pd.read_csv(\"career_village_challenge/data/matches1.csv\")\n",
        "matches2 = pd.read_csv(\"career_village_challenge/data/matches2.csv\")\n",
        "matches3 = pd.read_csv(\"career_village_challenge/data/matches3.csv\")\n",
        "matches = pd.concat([matches1,matches2,matches3])\n",
        "\n",
        "professionals = pd.read_csv(\"career_village_challenge/data/professionals.csv\")\n",
        "\n",
        "questions = pd.read_csv(\"career_village_challenge/data/questions.csv\")\n",
        "question_scores = pd.read_csv(\"career_village_challenge/data/question_scores.csv\")\n",
        "\n",
        "schools_members = pd.read_csv(\"career_village_challenge/data/school_memberships.csv\")\n",
        "students = pd.read_csv(\"career_village_challenge/data/students.csv\")\n",
        "\n",
        "tag_users = pd.read_csv(\"career_village_challenge/data/tag_users.csv\")\n",
        "tag_questions = pd.read_csv(\"career_village_challenge/data/tag_questions.csv\")\n",
        "tags = pd.read_csv(\"career_village_challenge/data/tags.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEGCAuv2wbKk"
      },
      "source": [
        "def get_user_tags(user_id):\n",
        "    user_tags = tag_users[tag_users[\"tag_users_user_id\"] == user_id][\"tag_users_tag_id\"]\n",
        "    tags_names =tags.loc[tags[\"tags_tag_id\"].isin(user_tags)]\n",
        "    return(tags)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyaMSjVwwbKk"
      },
      "source": [
        "def get_user_answers(user_id):\n",
        "    all_answers = answers.loc[answers[\"answers_author_id\"]==user_id]\n",
        "    return all_answers"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAWkQV05wbKk"
      },
      "source": [
        "def match_email_question(email_date):\n",
        "    f = lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S UTC+0000\")\n",
        "    b  =f(email_date)\n",
        "    t = questions[\"questions_date_added\"].apply(f)\n",
        "    return questions.iloc[(b-t).abs().argsort()[:1]]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmLZV_i7wbKk"
      },
      "source": [
        "# get only emails that were sent immediately after getting the question (ignore the weekly newsletter emails)\n",
        "immediate_emails = emails[emails[\"emails_frequency_level\"]==\"email_notification_immediate\"]\n",
        "\n",
        "# get the matches of the immediate emails only\n",
        "immediate_matches = matches[matches[\"matches_email_id\"].isin(immediate_emails[\"emails_id\"])]\n",
        "# get the emails that have their matches only (the data is missing the matches of some emails so we ignore those)\n",
        "immediate_emails = immediate_emails[immediate_emails[\"emails_id\"].isin(matches[\"matches_email_id\"])]\n",
        "# some renaming for convience\n",
        "immediate_emails = immediate_emails.rename(columns={'emails_id':\"id\"})\n",
        "immediate_matches = immediate_matches.rename(columns={'matches_email_id':\"id\"})\n",
        "# let's put the emails and their matches question id:\n",
        "emails_questions = pd.merge(immediate_emails, immediate_matches, how=\"left\", on=\"id\")\n",
        "#some renaming:\n",
        "emails_questions = emails_questions.rename(columns = {\"matches_question_id\": \"question_id\", \"emails_recipient_id\": \"professional_id\"})\n",
        "answers = answers.rename(columns = {\"answers_question_id\": \"question_id\", \"answers_author_id\": \"professional_id\"})\n",
        "\n",
        "# now, let's make a big data that has emails, questions sent, and answers. Note that some professionals provided more than\n",
        "# one answer to the same question. So this means the email Id will be repeated because it has two answers\n",
        "full_data = pd.merge(emails_questions, answers,how='left',  on=[\"professional_id\",\"question_id\" ])\n",
        "full_data = full_data.rename(columns = {\"id\": \"email_id\"})\n",
        "\n",
        "# get the target variable by looking ad the answer and putting 1 if it exists and 0 if not:\n",
        "target = full_data['answers_id'].fillna(0)\n",
        "target = pd.to_numeric(target, errors='coerce').fillna(1).astype(int) #here just turn str to NA then replace with 1\n",
        "full_data[\"q_answered?\"] = target\n",
        "\n",
        "# turn the email sent date into a datetime value instead of a string\n",
        "date_vectorizer = lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S UTC+0000\")\n",
        "full_data[\"emails_date_sent\"] = full_data[\"emails_date_sent\"].apply(date_vectorizer)\n",
        "# turn the asnwer added data to datetime value instead of a string (while ignoring the NAs)\n",
        "indices = full_data[\"answers_date_added\"][full_data[\"answers_date_added\"].notnull()].index.values\n",
        "full_data.loc[indices, \"answers_date_added\"] = full_data[\"answers_date_added\"][full_data[\"answers_date_added\"].notnull()].apply(date_vectorizer)\n",
        "#adding the time taken for each professional to answer a question\n",
        "full_data[\"time_taken\"] =  pd.to_datetime(full_data[\"answers_date_added\"]) - pd.to_datetime(full_data[\"emails_date_sent\"])\n",
        "\n",
        "# some people were too active and answered the question even before the email was sent to them. So that would lead\n",
        "# to a negative time_taken. So we fix that by putting a zero for the time they took (they answered it immediately)\n",
        "indices2 = full_data[\"time_taken\"][full_data[\"time_taken\"] < datetime.timedelta( days=0)].index.values\n",
        "full_data.loc[indices2, \"time_taken\"]=datetime.timedelta(days=0, seconds=0,minutes=0, hours=0 )\n",
        "# get all the tags of each question\n",
        "tag_questions_names = pd.merge(tag_questions.rename(columns = {\"tag_questions_tag_id\":\"tag_id\"}), tags.rename(columns = {\"tags_tag_id\":\"tag_id\"}),how='left',  on=[\"tag_id\" ])\n",
        "tag_questions_names = tag_questions_names.rename(columns ={\"tag_questions_question_id\":\"question_id\", \"tags_tag_name\":\"tag_name\"})\n",
        "questions_tags = tag_questions_names.groupby(\"question_id\")[\"tag_name\"].apply(list).reset_index(name=\"q_tags\")\n",
        "full_data = pd.merge(full_data,questions_tags,how='left',  on=[\"question_id\" ])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UktMe3AEwbKk"
      },
      "source": [
        "# creating a data for all the professionals\n",
        "professionals_dataset = pd.DataFrame(columns = [\"professional_id\"])\n",
        "professionals_dataset[\"professional_id\"] = professionals[\"professionals_id\"]\n",
        "# getting the response rate by counting the number of questions answered after the email was sent\n",
        "response = full_data.groupby(\"professional_id\").mean().drop(columns = [\"email_id\"]).reset_index()\n",
        "professionals_dataset = pd.merge(professionals_dataset, response,how='left',  on=[\"professional_id\" ])\n",
        "professionals_dataset = professionals_dataset.rename(columns = {\"q_answered?\": \"response_rate\"})\n",
        "\n",
        "# getting the average time they took to answer the question if they did\n",
        "grouped = full_data.groupby('professional_id')[\"time_taken\"]\n",
        "time_mean = grouped.apply(lambda x: np.mean(x))\n",
        "professionals_dataset = pd.merge(professionals_dataset, time_mean,how='left',  on=[\"professional_id\" ])\n",
        "professionals_dataset=  professionals_dataset.rename(columns ={\"time_taken\": \"avg_time_taken\"})\n",
        "# count the total number of questions that each professional answered (including those answered after email)\n",
        "answers_count = answers[\"professional_id\"].value_counts().reset_index().rename(columns = {\"professional_id\":\"number_q_answered\",\"index\":\"professional_id\",  })\n",
        "professionals_dataset = pd.merge(professionals_dataset, answers_count,how='left',  on=[\"professional_id\" ])\n",
        "professionals_dataset[\"number_q_answered\"]= professionals_dataset[\"number_q_answered\"].fillna(0)\n",
        "\n",
        "# get all the tags that each professional is following\n",
        "all_tags = pd.merge(tag_users.rename(columns = {\"tag_users_tag_id\": \"tag_id\"}),tags.rename(columns = {\"tags_tag_id\": \"tag_id\"}),how='left',  on=[\"tag_id\" ])\n",
        "foll_tags = all_tags.groupby('tag_users_user_id')['tags_tag_name'].apply(list).reset_index(name='following_tags').rename(columns = {\"tag_users_user_id\": \"professional_id\"})\n",
        "professionals_dataset = pd.merge(professionals_dataset, foll_tags,how='left',  on=[\"professional_id\" ])\n",
        "# get all the tags of the questions that he answered before\n",
        "a = full_data[[\"professional_id\",\"q_tags\"]][full_data[\"q_tags\"].notnull()].groupby(\"professional_id\")[\"q_tags\"].agg(sum)\n",
        "professionals_dataset = pd.merge(professionals_dataset, a,how='left',  on=[\"professional_id\" ])\n",
        "professionals_dataset = professionals_dataset.rename(columns = {\"q_tags\": \"prev_q_tags\"})\n",
        "# get the average score for each professional\n",
        "\n",
        "prof_score = pd.merge(answers[[\"professional_id\",\"answers_id\" ]], answers_scores.rename(columns = {\"id\":\"answers_id\"}),how='left',  on=[\"answers_id\" ]).drop(columns = [\"answers_id\"])\n",
        "score_mean = prof_score.groupby(\"professional_id\").mean().reset_index()\n",
        "professionals_dataset = pd.merge(professionals_dataset,score_mean,how='left',  on=[\"professional_id\" ]).rename(columns = {\"score\":\"avg_ansrs_score\"})\n",
        "professionals_dataset[\"avg_ansrs_score\"] = professionals_dataset[\"avg_ansrs_score\"].fillna(0)\n",
        "# get the number of groups that each professional is following\n",
        "prof_grp = group_members[\"group_memberships_user_id\"].value_counts().reset_index().rename(columns = {\"index\":\"professional_id\", \"group_memberships_user_id\":\"num_groups\"})\n",
        "professionals_dataset = pd.merge(professionals_dataset,prof_grp,how='left',  on=[\"professional_id\" ])\n",
        "# get the number of schools that each professional is following\n",
        "prof_schl = schools_members[\"school_memberships_user_id\"].value_counts().reset_index().rename(columns = {\"index\":\"professional_id\", \"school_memberships_user_id\":\"num_schools\"})\n",
        "professionals_dataset = pd.merge(professionals_dataset,prof_schl,how='left',  on=[\"professional_id\" ])\n",
        "\n",
        "#get the answers to email ratio (#answers/#emails sent) for each professional\n",
        "prof_emls = immediate_emails[\"emails_recipient_id\"].value_counts().reset_index().rename(columns = {\"index\":\"professional_id\", \"emails_recipient_id\":\"num_emails\"})\n",
        "professionals_dataset = pd.merge(professionals_dataset,prof_emls,how='left',  on=[\"professional_id\" ])\n",
        "professionals_dataset[\"answrs_emails_ratio\"] = professionals_dataset[\"number_q_answered\"] / professionals_dataset[\"num_emails\"]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFrS9g-3DMz8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "790a53e5-ae0b-4bd2-f970-a12e8e0a4d63"
      },
      "source": [
        "professionals_dataset = professionals_dataset.drop(columns=['Unnamed: 0_x', 'Unnamed: 0_y'])\n",
        "professionals_dataset.head(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>professional_id</th>\n",
              "      <th>response_rate</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>number_q_answered</th>\n",
              "      <th>following_tags</th>\n",
              "      <th>prev_q_tags</th>\n",
              "      <th>avg_ansrs_score</th>\n",
              "      <th>num_groups</th>\n",
              "      <th>num_schools</th>\n",
              "      <th>num_emails</th>\n",
              "      <th>answrs_emails_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9ced4ce7519049c0944147afb75a8ce3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f718dcf6d2ec4cb0a52a9db59d7f9e67</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>39.0</td>\n",
              "      <td>[consulting, education, consulting, education,...</td>\n",
              "      <td>[guidance-counselor, school-counselor, school,...</td>\n",
              "      <td>1.974359</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0.557143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>977428d851b24183b223be0eb8619a8c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>23.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.478261</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e2d57e5041a44f489288397c9904c2b2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    professional_id  ...  answrs_emails_ratio\n",
              "0  9ced4ce7519049c0944147afb75a8ce3  ...                  NaN\n",
              "1  f718dcf6d2ec4cb0a52a9db59d7f9e67  ...                  NaN\n",
              "2  0c673e046d824ec0ad0ebe012a0673e4  ...             0.557143\n",
              "3  977428d851b24183b223be0eb8619a8c  ...                  NaN\n",
              "4  e2d57e5041a44f489288397c9904c2b2  ...                  NaN\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsa6soeJf8mt"
      },
      "source": [
        "##NLP Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc7NkVipjmme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eabdd08f-8419-4a4c-e5d7-8e713c6bba6a"
      },
      "source": [
        "#Import functions for NLP\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from dateutil import parser\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY5DjGQOf-e7"
      },
      "source": [
        "#Functions for NLP\n",
        "\n",
        "\n",
        "def lowercase(input):\n",
        "  \"\"\"\n",
        "  Returns lowercase text\n",
        "  \"\"\"\n",
        "  return input.lower()\n",
        "\n",
        "def remove_punctuation(input):\n",
        "  \"\"\"\n",
        "  Returns text without punctuation\n",
        "  \"\"\"\n",
        "  return input.translate(str.maketrans('','', string.punctuation))\n",
        "\n",
        "def remove_whitespaces(input):\n",
        "  \"\"\"\n",
        "  Returns text without extra whitespaces\n",
        "  \"\"\"\n",
        "  return \" \".join(input.split())\n",
        "  \n",
        "def remove_html_tags(input):\n",
        "  \"\"\"\n",
        "  Returns text without HTML tags\n",
        "  \"\"\"\n",
        "  soup = BeautifulSoup(input, \"html.parser\")\n",
        "  stripped_input = soup.get_text(separator=\" \")\n",
        "  return stripped_input\n",
        "\n",
        "def tokenize(input):\n",
        "  \"\"\"\n",
        "  Returns tokenized version of text\n",
        "  \"\"\"\n",
        "  return word_tokenize(input)\n",
        "\n",
        "def remove_stop_words(input):\n",
        "  \"\"\"\n",
        "  Returns text without stop words\n",
        "  \"\"\"\n",
        "  input = word_tokenize(input)\n",
        "  return [word for word in input if word not in stopwords.words('english')]\n",
        "\n",
        "def lemmatize(input):\n",
        "  \"\"\"\n",
        "  Lemmatizes input using NLTK's WordNetLemmatizer\n",
        "  \"\"\"\n",
        "  lemmatizer=WordNetLemmatizer()\n",
        "  input_str=word_tokenize(input)\n",
        "  new_words = []\n",
        "  for word in input_str:\n",
        "    new_words.append(lemmatizer.lemmatize(word))\n",
        "  return ' '.join(new_words)\n",
        "\n",
        "\n",
        "def nlp_pipeline(input):\n",
        "  \"\"\"\n",
        "  Function that calls all other functions together to perform NLP on a given text\n",
        "  \"\"\"\n",
        "  return lemmatize(' '.join(remove_stop_words(remove_whitespaces(remove_punctuation(remove_html_tags(lowercase(input)))))))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbZTAHtjgoRJ"
      },
      "source": [
        "##LDA Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_L2bl4fjzwv"
      },
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
        "\n",
        "#Turn tags into a set for faster checking of whether a tag exists or not\n",
        "unique_tags = set(tags['tags_tag_name'])\n",
        "\n",
        "def find_topics(question_body):\n",
        "  \"\"\"\n",
        "  Function that takes a question as an input, and finds the two most important topics/tags\n",
        "  If the found topics exist in the already existing database of tags, we add these tags\n",
        "  to the professional who answered the question\n",
        "  \"\"\"\n",
        "  try:\n",
        "    text = nlp_pipeline(question_body)\n",
        "    count_vectorizer = CountVectorizer(stop_words='english')\n",
        "    count_data = count_vectorizer.fit_transform([text])\n",
        "    # One topic that has an avg of two words because most questions had 1/2 tags\n",
        "    number_topics = 1\n",
        "    number_words = 2\n",
        "    # Create and fit the LDA model\n",
        "    lda = LDA(n_components=number_topics, n_jobs=-1)\n",
        "    lda.fit(count_data)\n",
        "\n",
        "    words = count_vectorizer.get_feature_names()\n",
        "\n",
        "    #Get topics from model. They are represented as a list e.g. ['military','army']\n",
        "    topics = [[words[i] for i in topic.argsort()[:-number_words - 1:-1]] for (topic_idx, topic) in enumerate(lda.components_)]\n",
        "    topics = np.array(topics).ravel()\n",
        "    #Only use topics for which a tag already exists\n",
        "    existing_topics = set.intersection(set(topics),unique_tags)\n",
        "  \n",
        "  #A few question bodies don't work with LDA so this exception just prints them out and ignores them\n",
        "  except:\n",
        "    print(question_body)\n",
        "    return (question_body)\n",
        "\n",
        "  return existing_topics"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZHnZlKcgw6K"
      },
      "source": [
        "### Filter questions data for LDA function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Undu_V1VwbKm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "ec8561c6-aaf8-47ea-f6c0-931a3dc04063"
      },
      "source": [
        "# let's get the answers' authors first:\n",
        "my_answers_authors = answers.drop(columns = [\"answers_date_added\", \"answers_body\"])\n",
        "my_answers_authors.head(1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers_id</th>\n",
              "      <th>professional_id</th>\n",
              "      <th>question_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         answers_id  ...                       question_id\n",
              "0  4e5f01128cae4f6d8fd697cec5dca60c  ...  332a511f1569444485cf7a7a556a5e54\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Awot992fkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "c4fde78f-98fc-469d-c60d-1180723ce551"
      },
      "source": [
        "# let's now get the questions_body with the question id:\n",
        "my_questions_body = questions[[\"questions_id\", \"questions_body\"]].rename(columns = {\"questions_id\":\"question_id\"})\n",
        "my_questions_body.head(1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>questions_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        question_id                                     questions_body\n",
              "0  332a511f1569444485cf7a7a556a5e54  What  is  a  maths  teacher?   what  is  a  ma..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yCGNVe92hew",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "d63de113-c2dc-4b71-8051-1383cb284cc6"
      },
      "source": [
        "# let's merge these together:\n",
        "add_them = pd.merge(my_answers_authors,my_questions_body,how='left',  on=[\"question_id\" ])\n",
        "add_them.head(1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers_id</th>\n",
              "      <th>professional_id</th>\n",
              "      <th>question_id</th>\n",
              "      <th>questions_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         answers_id  ...                                     questions_body\n",
              "0  4e5f01128cae4f6d8fd697cec5dca60c  ...  What  is  a  maths  teacher?   what  is  a  ma...\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Glpcfbnq2wMJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "60a7d9a9-4e01-4548-b25d-2874f5f258ce"
      },
      "source": [
        "# let's drop the columns that we don't need:\n",
        "our_final_data = add_them.drop(columns = [\"answers_id\", \"question_id\"])\n",
        "our_final_data.head(1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>professional_id</th>\n",
              "      <th>questions_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    professional_id                                     questions_body\n",
              "0  36ff3b3666df400f956f8335cf53e09e  What  is  a  maths  teacher?   what  is  a  ma..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muuwdKALg2Fj"
      },
      "source": [
        "### Apply LDA Function on questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RhnvLsMjo4r"
      },
      "source": [
        "# let's apply the function and get our new tags:\n",
        "new_tags= our_final_data[\"questions_body\"].apply(find_topics).values\n",
        "# let's add it as a column:\n",
        "our_final_data[\"new_tags\"] = new_tags\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j-03YGY3B0I"
      },
      "source": [
        "\"\"\"\n",
        "Alternatively just import the results from a pickle file\n",
        "import pickle\n",
        "f = open('store.pckl', 'rb')\n",
        "new_tags = pickle.load(f)\n",
        "f.close()\n",
        "our_final_data[\"new_tags\"] = new_tags\n",
        "\"\"\""
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqbQKD2E3qZO"
      },
      "source": [
        "#group the tags of the same professionals in a list (this will be many tags for each professionl because \n",
        "# for each question they answer, they get two new tags)\n",
        "our_final_data = our_final_data.groupby(\"professional_id\")[\"new_tags\"].apply(list).reset_index()\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF-TTOG27pxZ"
      },
      "source": [
        "our_final_data['new_tags'] = our_final_data['new_tags'].apply(lambda x: list(set.union(*x)))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf-xEco83uo_"
      },
      "source": [
        "# finally, let's merge the new tags with the prev tags we had:\n",
        "toy = pd.merge(professionals_dataset,our_final_data,how='left',  on=[\"professional_id\" ])\n",
        "\n",
        "#Fixed a previous bug here\n",
        "professionals_dataset['prev_q_tags'].update(toy.pop('new_tags'))\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFO-51Bz33dz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "3132f70a-a34e-48f6-bbd7-5bf2bd382574"
      },
      "source": [
        "# final data: \n",
        "professionals_dataset.head(5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>professional_id</th>\n",
              "      <th>response_rate</th>\n",
              "      <th>avg_time_taken</th>\n",
              "      <th>number_q_answered</th>\n",
              "      <th>following_tags</th>\n",
              "      <th>prev_q_tags</th>\n",
              "      <th>avg_ansrs_score</th>\n",
              "      <th>num_groups</th>\n",
              "      <th>num_schools</th>\n",
              "      <th>num_emails</th>\n",
              "      <th>answrs_emails_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9ced4ce7519049c0944147afb75a8ce3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[resume, consulting]</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f718dcf6d2ec4cb0a52a9db59d7f9e67</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaT</td>\n",
              "      <td>39.0</td>\n",
              "      <td>[consulting, education, consulting, education,...</td>\n",
              "      <td>[judge, resume, anesthesiologist, want, year, ...</td>\n",
              "      <td>1.974359</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0.557143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>977428d851b24183b223be0eb8619a8c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>23.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[investigation, want, make, wondering, major, ...</td>\n",
              "      <td>1.478261</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e2d57e5041a44f489288397c9904c2b2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    professional_id  ...  answrs_emails_ratio\n",
              "0  9ced4ce7519049c0944147afb75a8ce3  ...                  NaN\n",
              "1  f718dcf6d2ec4cb0a52a9db59d7f9e67  ...                  NaN\n",
              "2  0c673e046d824ec0ad0ebe012a0673e4  ...             0.557143\n",
              "3  977428d851b24183b223be0eb8619a8c  ...                  NaN\n",
              "4  e2d57e5041a44f489288397c9904c2b2  ...                  NaN\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bXgjVHoZ_Rk"
      },
      "source": [
        "### Filter answers data for LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnwgEJThPr52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "408b6c9d-3741-4ea6-e06f-69072d945dc6"
      },
      "source": [
        "# let's get the answers' authors first:\n",
        "my_answers_authors = answers.drop(columns = [\"answers_date_added\", \"answers_body\"])\n",
        "my_answers_authors.head(1)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers_id</th>\n",
              "      <th>professional_id</th>\n",
              "      <th>question_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         answers_id  ...                       question_id\n",
              "0  4e5f01128cae4f6d8fd697cec5dca60c  ...  332a511f1569444485cf7a7a556a5e54\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "nF-oTGiZl_Rh",
        "outputId": "b4525fe9-7605-4440-87ff-ea7c2eae2418"
      },
      "source": [
        "# let's now get the answers_body with the question id:\n",
        "my_answers_body = answers[[\"answers_id\", \"answers_body\"]].rename(columns = {\"answers_id\":\"answers_id\"})\n",
        "my_answers_body.head(1)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers_id</th>\n",
              "      <th>answers_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
              "      <td>&lt;p&gt;Hi!&lt;/p&gt;\\n&lt;p&gt;You are asking a very interesti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         answers_id                                       answers_body\n",
              "0  4e5f01128cae4f6d8fd697cec5dca60c  <p>Hi!</p>\\n<p>You are asking a very interesti..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "WKE-VFDDmRHx",
        "outputId": "be5655fa-3ce3-4211-ca29-1c6dd97e8965"
      },
      "source": [
        "# let's merge these together:\n",
        "add_them = pd.merge(my_answers_authors,my_answers_body,how='left',  on=[\"answers_id\" ])\n",
        "add_them.head(1)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers_id</th>\n",
              "      <th>professional_id</th>\n",
              "      <th>question_id</th>\n",
              "      <th>answers_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
              "      <td>&lt;p&gt;Hi!&lt;/p&gt;\\n&lt;p&gt;You are asking a very interesti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         answers_id  ...                                       answers_body\n",
              "0  4e5f01128cae4f6d8fd697cec5dca60c  ...  <p>Hi!</p>\\n<p>You are asking a very interesti...\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "gk7n1xAnmi3Q",
        "outputId": "6809ea7c-7f5f-4f44-f1ae-5488aed672b4"
      },
      "source": [
        "# let's drop the columns that we don't need:\n",
        "our_final_data = add_them.drop(columns = [\"answers_id\", \"question_id\"])\n",
        "our_final_data.head(1)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>professional_id</th>\n",
              "      <th>answers_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
              "      <td>&lt;p&gt;Hi!&lt;/p&gt;\\n&lt;p&gt;You are asking a very interesti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    professional_id                                       answers_body\n",
              "0  36ff3b3666df400f956f8335cf53e09e  <p>Hi!</p>\\n<p>You are asking a very interesti..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoQaHr06hkYi"
      },
      "source": [
        "###Apply LDA function on answers data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RL4AqbKmlr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f4379ec-368e-46f8-ce11-da73fc29163b"
      },
      "source": [
        "# let's apply the function and get our new tags:\n",
        "\n",
        "new_tags= our_final_data[\"answers_body\"].apply(find_topics).values\n",
        "\n",
        "# let's add it as a column:\n",
        "our_final_data[\"new_tags\"] = new_tags\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "<p><br></p>\n",
            "<p><br></p>\n",
            "<p><br></p>\n",
            "<p><br></p>\n",
            "<p>Not at all.</p>\n",
            "<p>No</p>\n",
            "<p>Whatever you do, do it well!</p>\n",
            "<p>No.</p>\n",
            "<p>This just in - no </p>\n",
            "<p>C and c++. </p>\n",
            "<p><br></p>\n",
            "<p>\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</p>\n",
            "I do\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDNbsrN2y949"
      },
      "source": [
        "\"\"\"\n",
        "#Alternatively just import the results from a pickle file\n",
        "import pickle\n",
        "f = open('store_answers.pckl', 'rb')\n",
        "new_tags = pickle.load(f)\n",
        "f.close()\n",
        "our_final_data[\"new_tags\"] = new_tags\n",
        "\"\"\""
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D05qdNwAjAwh"
      },
      "source": [
        "#group the tags of the same professionals in a list (this will be many tags for each professionl because \n",
        "# for each question they answer, they get two new tags)\n",
        "our_final_data = our_final_data.groupby(\"professional_id\")[\"new_tags\"].apply(list).reset_index()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-TXtVIdjFbY"
      },
      "source": [
        "our_final_data['new_tags'] = our_final_data['new_tags'].apply(lambda x: list(set.union(*x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS65kJ3fjIX3"
      },
      "source": [
        "# finally, let's merge the new tags with the prev tags we had:\n",
        "toy = pd.merge(professionals_dataset,our_final_data,how='left',  on=[\"professional_id\" ])\n",
        "\n",
        "#Fixed a previous bug here\n",
        "professionals_dataset['following_tags'].update(toy.pop('new_tags'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFBC5dfsjKWn"
      },
      "source": [
        "# final data: \n",
        "professionals_dataset.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CGQGxkElPiT"
      },
      "source": [
        "-------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHrqfg3a4pRx"
      },
      "source": [
        "#Clustering model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phf2yw6W4uNk"
      },
      "source": [
        "#Download ~800mb spacy model because it is MUCH more accurate at semantic similarity\n",
        "!python -m spacy download en_core_web_lg\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRLWThbxh5Bg"
      },
      "source": [
        "#Import model for similarity calculation\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANhBw_sc4wqR"
      },
      "source": [
        "#Use spacy to find similarities between tags\n",
        "tag_list =  list(tags['tags_tag_name'])\n",
        "#3871 contains nan so delete it\n",
        "del tag_list[3871]\n",
        "\n",
        "#Get rid of hyphens and turn the split words into an extra tag\n",
        "corpus = ' '.join(list(tag_list)).replace('-',' ')\n",
        "words = corpus.split()\n",
        "corpus = \" \".join(sorted(set(words), key=words.index))\n",
        "\n",
        "#Apply the model on our dataset of tags\n",
        "tokens = nlp(corpus)\n",
        "\n",
        "#Convert tags into vectors for our clustering model\n",
        "word_vectors = []\n",
        "for i in tokens:\n",
        "  word_vectors.append(i.vector)\n",
        "word_vectors = np.array(word_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5_qbqbA_vkM"
      },
      "source": [
        "#Fit model\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "#Use cosine because spacy uses cosine. min_samples = 2 because a cluster should have atleast 2 similar words\n",
        "dbscan = DBSCAN(metric='cosine', eps=0.3, min_samples=2).fit(word_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6baQ7dL_7nz"
      },
      "source": [
        "#Function for returning label prediction since there is no builtin function\n",
        "def dbscan_predict(model, X):\n",
        "\n",
        "    nr_samples = X.shape[0]\n",
        "\n",
        "    y_new = np.ones(shape=nr_samples, dtype=int) * -1\n",
        "\n",
        "    for i in range(nr_samples):\n",
        "        diff = model.components_ - X[i, :]  # NumPy broadcasting\n",
        "\n",
        "        dist = np.linalg.norm(diff, axis=1)  # Euclidean distance\n",
        "\n",
        "        shortest_dist_idx = np.argmin(dist)\n",
        "\n",
        "        if dist[shortest_dist_idx] < model.eps:\n",
        "            y_new[i] = model.labels_[model.core_sample_indices_[shortest_dist_idx]]\n",
        "\n",
        "    return y_new\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n89Sj_UAv_Z"
      },
      "source": [
        "test_words = ' '.join(['university', 'colleges', 'education', 'courses']).replace('-', ' ')\n",
        "test_tokens = nlp(test_words)\n",
        "\n",
        "test_vectors = []\n",
        "for i in test_tokens:\n",
        "  test_vectors.append(i.vector)\n",
        "test_vectors = np.array(test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M91Z7EPbSgq"
      },
      "source": [
        "print('Label for university:'+str(dbscan_predict(dbscan,np.array([test_vectors[0]]))[0]))\n",
        "print('Label for colleges:'+str(dbscan_predict(dbscan,np.array([test_vectors[1]]))[0]))\n",
        "print('Label for education:'+str(dbscan_predict(dbscan,np.array([test_vectors[2]]))[0]))\n",
        "print('Label for courses:'+str(dbscan_predict(dbscan,np.array([test_vectors[3]]))[0]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}