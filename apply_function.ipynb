{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_users = pd.read_csv(\"tag_users.csv\")\n",
    "tag_questions = pd.read_csv(\"tag_questions.csv\")\n",
    "tags = pd.read_csv(\"tags.csv\")\n",
    "professionals = pd.read_csv(\"professionals.csv\")\n",
    "answers = pd.read_csv(\"answers.csv\")\n",
    "emails = pd.read_csv(\"emails.csv\")\n",
    "questions = pd.read_csv(\"questions.csv\")\n",
    "matches = pd.read_csv(\"matches.csv\")\n",
    "answers_scores = pd.read_csv(\"answer_scores.csv\")\n",
    "group_members = pd.read_csv(\"group_memberships.csv\")\n",
    "schools_members = pd.read_csv(\"school_memberships.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_tags(user_id):\n",
    "    user_tags = tag_users[tag_users[\"tag_users_user_id\"] == user_id][\"tag_users_tag_id\"]\n",
    "    tags_names =tags.loc[tags[\"tags_tag_id\"].isin(user_tags)]\n",
    "    return(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_answers(user_id):\n",
    "    all_answers = answers.loc[answers[\"answers_author_id\"]==user_id]\n",
    "    return all_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_email_question(email_date):\n",
    "    f = lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S UTC+0000\")\n",
    "    b  =f(email_date)\n",
    "    t = questions[\"questions_date_added\"].apply(f)\n",
    "    return questions.iloc[(b-t).abs().argsort()[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "immediate_emails = emails[emails[\"emails_frequency_level\"]==\"email_notification_immediate\"]\n",
    "immediate_matches = matches[matches[\"matches_email_id\"].isin(immediate_emails[\"emails_id\"])]\n",
    "immediate_emails = immediate_emails[immediate_emails[\"emails_id\"].isin(matches[\"matches_email_id\"])]\n",
    "\n",
    "immediate_emails = immediate_emails.rename(columns={'emails_id':\"id\"})\n",
    "immediate_matches = immediate_matches.rename(columns={'matches_email_id':\"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_questions = pd.merge(immediate_emails, immediate_matches, how=\"left\", on=\"id\")\n",
    "emails_questions = emails_questions.rename(columns = {\"matches_question_id\": \"question_id\", \"emails_recipient_id\": \"professional_id\"})\n",
    "answers = answers.rename(columns = {\"answers_question_id\": \"question_id\", \"answers_author_id\": \"professional_id\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.merge(emails_questions, answers,how='left',  on=[\"professional_id\",\"question_id\" ])\n",
    "target = full_data['answers_id'].fillna(0)\n",
    "target = pd.to_numeric(target, errors='coerce').fillna(1).astype(int)\n",
    "full_data[\"q_answered\"] = target\n",
    "full_data = full_data.rename(columns = {\"id\": \"email_id\"})\n",
    "date_vectorizer = lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S UTC+0000\")\n",
    "full_data[\"emails_date_sent\"] = full_data[\"emails_date_sent\"].apply(date_vectorizer)\n",
    "indices = full_data[\"answers_date_added\"][full_data[\"answers_date_added\"].notnull()].index.values\n",
    "full_data.loc[indices, \"answers_date_added\"] = full_data[\"answers_date_added\"][full_data[\"answers_date_added\"].notnull()].apply(date_vectorizer)\n",
    "full_data[\"time_taken\"] =  pd.to_datetime(full_data[\"answers_date_added\"]) - pd.to_datetime(full_data[\"emails_date_sent\"])\n",
    "indices2 = full_data[\"time_taken\"][full_data[\"time_taken\"] < datetime.timedelta( days=0)].index.values\n",
    "full_data.loc[indices2, \"time_taken\"]=datetime.timedelta(days=0, seconds=0,minutes=0, hours=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = full_data.groupby(\"professional_id\").mean().drop(columns = [\"email_id\"]).reset_index()\n",
    "professionals_dataset = pd.DataFrame(columns = [\"professional_id\"])\n",
    "professionals_dataset[\"professional_id\"] = professionals[\"professionals_id\"]\n",
    "professionals_dataset = pd.merge(professionals_dataset, response,how='left',  on=[\"professional_id\" ])\n",
    "professionals_dataset = professionals_dataset.rename(columns = {\"q_answered\": \"response_rate\"})\n",
    "grouped = full_data.groupby('professional_id')[\"time_taken\"]\n",
    "time_mean = grouped.apply(lambda x: np.mean(x))\n",
    "professionals_dataset = pd.merge(professionals_dataset, time_mean,how='left',  on=[\"professional_id\" ])\n",
    "professionals_dataset=  professionals_dataset.rename(columns ={\"time_taken\": \"avg_time_taken\"})\n",
    "answers_count = answers[\"professional_id\"].value_counts().reset_index().rename(columns = {\"professional_id\":\"number_q_answered\",\"index\":\"professional_id\",  })\n",
    "professionals_dataset = pd.merge(professionals_dataset, answers_count,how='left',  on=[\"professional_id\" ])\n",
    "all_tags = pd.merge(tag_users.rename(columns = {\"tag_users_tag_id\": \"tag_id\"}),tags.rename(columns = {\"tags_tag_id\": \"tag_id\"}),how='left',  on=[\"tag_id\" ])\n",
    "foll_tags = all_tags.groupby('tag_users_user_id')['tags_tag_name'].apply(list).reset_index(name='following_tags').rename(columns = {\"tag_users_user_id\": \"professional_id\"})\n",
    "professionals_dataset = pd.merge(professionals_dataset, foll_tags,how='left',  on=[\"professional_id\" ])\n",
    "a = pd.merge(answers[\"question_id\"].reset_index(), tag_questions.rename(columns = {\"tag_questions_question_id\": \"question_id\"}),how='left',  on=[\"question_id\" ])\n",
    "b = pd.merge(a.rename(columns = {\"tag_questions_tag_id\":\"tags_tag_id\"}), tags,how='left',  on=[\"tags_tag_id\" ]).drop(columns = [\"index\", \"tags_tag_id\"])\n",
    "c = pd.merge(b, answers,how='left',  on=[\"question_id\" ]).drop(columns = [\"answers_id\", \"answers_date_added\", \"answers_body\", \"question_id\"])\n",
    "d = c.groupby(\"professional_id\")[\"tags_tag_name\"].apply(list).reset_index()\n",
    "professionals_dataset = pd.merge(professionals_dataset, d.rename(columns = {\"tags_tag_name\": \"prev_q_tags\"}),how='left',  on=[\"professional_id\" ])\n",
    "prof_score = pd.merge(answers[[\"professional_id\",\"answers_id\" ]], answers_scores.rename(columns = {\"id\":\"answers_id\"}),how='left',  on=[\"answers_id\" ]).drop(columns = [\"answers_id\"])\n",
    "prof_score.groupby(\"professional_id\").mean().reset_index()\n",
    "professionals_dataset = pd.merge(professionals_dataset,prof_score,how='left',  on=[\"professional_id\" ]).rename(columns = {\"score\":\"avg_ansrs_score\"})\n",
    "prof_grp = group_members[\"group_memberships_user_id\"].value_counts().reset_index().rename(columns = {\"index\":\"professional_id\", \"group_memberships_user_id\":\"num_groups\"})\n",
    "professionals_dataset = pd.merge(professionals_dataset,prof_grp,how='left',  on=[\"professional_id\" ])\n",
    "prof_schl = schools_members[\"school_memberships_user_id\"].value_counts().reset_index().rename(columns = {\"index\":\"professional_id\", \"school_memberships_user_id\":\"num_schools\"})\n",
    "professionals_dataset = pd.merge(professionals_dataset,prof_schl,how='left',  on=[\"professional_id\" ])\n",
    "prof_emls = immediate_emails[\"emails_recipient_id\"].value_counts().reset_index().rename(columns = {\"index\":\"professional_id\", \"emails_recipient_id\":\"num_emails\"})\n",
    "professionals_dataset = pd.merge(professionals_dataset,prof_emls,how='left',  on=[\"professional_id\" ])\n",
    "professionals_dataset[\"answrs_emails_ratio\"] = professionals_dataset[\"number_q_answered\"] / professionals_dataset[\"num_emails\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professional_id</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>avg_time_taken</th>\n",
       "      <th>number_q_answered</th>\n",
       "      <th>following_tags</th>\n",
       "      <th>prev_q_tags</th>\n",
       "      <th>avg_ansrs_score</th>\n",
       "      <th>num_groups</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>num_emails</th>\n",
       "      <th>answrs_emails_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9ced4ce7519049c0944147afb75a8ce3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[consulting, resume, consulting, resume, consu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    professional_id  response_rate avg_time_taken  \\\n",
       "0  9ced4ce7519049c0944147afb75a8ce3            NaN            NaT   \n",
       "\n",
       "   number_q_answered following_tags  \\\n",
       "0                1.0            NaN   \n",
       "\n",
       "                                         prev_q_tags  avg_ansrs_score  \\\n",
       "0  [consulting, resume, consulting, resume, consu...              5.0   \n",
       "\n",
       "   num_groups  num_schools  num_emails  answrs_emails_ratio  \n",
       "0         NaN          NaN         NaN                  NaN  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "professionals_dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gaber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gaber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gaber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "import shutil\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def lowercase(input):\n",
    "  return input.lower()\n",
    "\n",
    "def remove_punctuation(input):\n",
    "  return input.translate(str.maketrans('','', string.punctuation))\n",
    "\n",
    "def remove_whitespaces(input):\n",
    "  return \" \".join(input.split())\n",
    "  \n",
    "def remove_html_tags(input):\n",
    "    soup = BeautifulSoup(input, \"html.parser\")\n",
    "    stripped_input = soup.get_text(separator=\" \")\n",
    "    return stripped_input\n",
    "\n",
    "def tokenize(input):\n",
    "  return word_tokenize(input)\n",
    "\n",
    "def remove_stop_words(input):\n",
    "  input = word_tokenize(input)\n",
    "  return [word for word in input if word not in stopwords.words('english')]\n",
    "\n",
    "def lemmatize(input):\n",
    "  lemmatizer=WordNetLemmatizer()\n",
    "  input_str=word_tokenize(input)\n",
    "  new_words = []\n",
    "  for word in input_str:\n",
    "    new_words.append(lemmatizer.lemmatize(word))\n",
    "  return ' '.join(new_words)\n",
    "\n",
    "#Function that calls all other functions together to perform NLP on a given text\n",
    "def nlp_pipeline(input):\n",
    "  return lemmatize(' '.join(remove_stop_words(remove_whitespaces(remove_punctuation(remove_html_tags(lowercase(input)))))))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "#Turn tags into a set for faster checking of whether a tag exists or not\n",
    "unique_tags = set(tags['tags_tag_name'])\n",
    "\n",
    "def find_topics(question_body):\n",
    "  \"\"\"\n",
    "  Function that takes a question as an input, and finds the two most important topics/tags\n",
    "  If the found topics exist in the already existing database of tags, we add these tags\n",
    "  to the professional who answered the question\n",
    "  \"\"\"\n",
    "\n",
    "  text = nlp_pipeline(question_body)\n",
    "  count_vectorizer = CountVectorizer(stop_words='english')\n",
    "  count_data = count_vectorizer.fit_transform([text])\n",
    "  # One topic that has an avg of two words because most questions had 1/2 tags\n",
    "  number_topics = 1\n",
    "  number_words = 2\n",
    "  # Create and fit the LDA model\n",
    "  lda = LDA(n_components=number_topics, n_jobs=-1)\n",
    "  lda.fit(count_data)\n",
    "\n",
    "  words = count_vectorizer.get_feature_names()\n",
    "\n",
    "  #Get topics from model. They are represented as a list e.g. ['military','army']\n",
    "  topics = [[words[i] for i in topic.argsort()[:-number_words - 1:-1]] for (topic_idx, topic) in enumerate(lda.components_)]\n",
    "  topics = np.array(topics).ravel()\n",
    "  #Only use topics for which a tag already exists\n",
    "  existing_topics = []\n",
    "  for tag in topics:\n",
    "    if tag in unique_tags:\n",
    "      existing_topics.append(tag)\n",
    "\n",
    "  return existing_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'finance']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_body = \"Hello, can you please give me advice on which courses to take to have a career in finance?\"\n",
    "find_topics(question_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm planning on going abroad for my first job. It will be a teaching job and I don't have any serious career ideas. I don't know what job I would be working if I stay home instead so I'm assuming staying or leaving won't makeba huge difference in what I care about, unless I find something before my first job. I can think of ways that going abroad can be seen as good and bad. I do not know which side respectable employers willl side with. #working-abroad #employment- #overseas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['job', 'know']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_body = questions[\"questions_body\"][2]\n",
    "print(question_body)\n",
    "find_topics(question_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a toy function that is fast:\n",
    "question_body = \"Hello, can you please give me advice on which courses to take to have a career in finance?\"\n",
    "def find_topics_toy(question_body):\n",
    "    return question_body.split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers_id</th>\n",
       "      <th>professional_id</th>\n",
       "      <th>question_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         answers_id                   professional_id  \\\n",
       "0  4e5f01128cae4f6d8fd697cec5dca60c  36ff3b3666df400f956f8335cf53e09e   \n",
       "\n",
       "                        question_id  \n",
       "0  332a511f1569444485cf7a7a556a5e54  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's get the answers' authors first:\n",
    "my_answers_authors = answers.drop(columns = [\"answers_date_added\", \"answers_body\"])\n",
    "my_answers_authors.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>questions_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54   \n",
       "\n",
       "                                      questions_body  \n",
       "0  What  is  a  maths  teacher?   what  is  a  ma...  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's now get the questions_body with the question id:\n",
    "my_questions_body = questions[[\"questions_id\", \"questions_body\"]].rename(columns = {\"questions_id\":\"question_id\"})\n",
    "my_questions_body.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers_id</th>\n",
       "      <th>professional_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>questions_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         answers_id                   professional_id  \\\n",
       "0  4e5f01128cae4f6d8fd697cec5dca60c  36ff3b3666df400f956f8335cf53e09e   \n",
       "\n",
       "                        question_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54   \n",
       "\n",
       "                                      questions_body  \n",
       "0  What  is  a  maths  teacher?   what  is  a  ma...  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's merge these together:\n",
    "add_them = pd.merge(my_answers_authors,my_questions_body,how='left',  on=[\"question_id\" ])\n",
    "add_them.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professional_id</th>\n",
       "      <th>questions_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    professional_id  \\\n",
       "0  36ff3b3666df400f956f8335cf53e09e   \n",
       "\n",
       "                                      questions_body  \n",
       "0  What  is  a  maths  teacher?   what  is  a  ma...  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's drop the columns that we don't need:\n",
    "our_final_data = add_them.drop(columns = [\"answers_id\", \"question_id\"])\n",
    "our_final_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's apply the function and get our new tags:\n",
    "new_tags= our_final_data[\"questions_body\"].apply(find_topics_toy).values\n",
    "\n",
    "# let's add it as a column:\n",
    "our_final_data[\"new_tags\"] = new_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a small issue, the professionals in that dataset are not unique because they answered different questions and\n",
    "# from each question, they get a unique new two tags. So let's group the tags of the same professionals together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the tags of the same professionals in a list (this will be many tags for each professionl because \n",
    "# for each question they answer, they get two new tags)\n",
    "our_final_data = our_final_data.groupby(\"professional_id\")[\"new_tags\"].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, let's merge the new tags with the prev tags we had:\n",
    "toy = pd.merge(professionals_dataset,our_final_data,how='left',  on=[\"professional_id\" ])\n",
    "professionals_dataset[\"prev_q_tags\"] = toy[\"prev_q_tags\"]+toy[\"new_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professional_id</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>avg_time_taken</th>\n",
       "      <th>number_q_answered</th>\n",
       "      <th>following_tags</th>\n",
       "      <th>prev_q_tags</th>\n",
       "      <th>avg_ansrs_score</th>\n",
       "      <th>num_groups</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>num_emails</th>\n",
       "      <th>answrs_emails_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9ced4ce7519049c0944147afb75a8ce3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[consulting, resume, consulting, resume, consu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f718dcf6d2ec4cb0a52a9db59d7f9e67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>39.0</td>\n",
       "      <td>[consulting, education, consulting, education,...</td>\n",
       "      <td>[experience, healthcare, doctor, anesthesiolog...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>39.0</td>\n",
       "      <td>[consulting, education, consulting, education,...</td>\n",
       "      <td>[experience, healthcare, doctor, anesthesiolog...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>39.0</td>\n",
       "      <td>[consulting, education, consulting, education,...</td>\n",
       "      <td>[experience, healthcare, doctor, anesthesiolog...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68186</th>\n",
       "      <td>9f267950ab8e43e2afcf564327049297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[broadcast-media]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68187</th>\n",
       "      <td>4a7e1e5dd884488da283e1cab6ad11e0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[telecommunications, firstnet, #inbuildingsolu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68188</th>\n",
       "      <td>ea75c5fce38348e0a151c3c346929e6a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[computer-software, electrical-engineering, ha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68189</th>\n",
       "      <td>34f6222c3c02480ca2df8a3e4ba878d0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[telecommunications]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68190</th>\n",
       "      <td>ebc523719253485bb35e94ca561eb051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[communications, mentoring, coaching, organiza...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68191 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        professional_id  response_rate avg_time_taken  \\\n",
       "0      9ced4ce7519049c0944147afb75a8ce3            NaN            NaT   \n",
       "1      f718dcf6d2ec4cb0a52a9db59d7f9e67            NaN            NaT   \n",
       "2      0c673e046d824ec0ad0ebe012a0673e4            0.0            NaT   \n",
       "3      0c673e046d824ec0ad0ebe012a0673e4            0.0            NaT   \n",
       "4      0c673e046d824ec0ad0ebe012a0673e4            0.0            NaT   \n",
       "...                                 ...            ...            ...   \n",
       "68186  9f267950ab8e43e2afcf564327049297            NaN            NaT   \n",
       "68187  4a7e1e5dd884488da283e1cab6ad11e0            NaN            NaT   \n",
       "68188  ea75c5fce38348e0a151c3c346929e6a            NaN            NaT   \n",
       "68189  34f6222c3c02480ca2df8a3e4ba878d0            NaN            NaT   \n",
       "68190  ebc523719253485bb35e94ca561eb051            NaN            NaT   \n",
       "\n",
       "       number_q_answered                                     following_tags  \\\n",
       "0                    1.0                                                NaN   \n",
       "1                    NaN                                                NaN   \n",
       "2                   39.0  [consulting, education, consulting, education,...   \n",
       "3                   39.0  [consulting, education, consulting, education,...   \n",
       "4                   39.0  [consulting, education, consulting, education,...   \n",
       "...                  ...                                                ...   \n",
       "68186                NaN                                  [broadcast-media]   \n",
       "68187                NaN  [telecommunications, firstnet, #inbuildingsolu...   \n",
       "68188                NaN  [computer-software, electrical-engineering, ha...   \n",
       "68189                NaN                               [telecommunications]   \n",
       "68190                NaN  [communications, mentoring, coaching, organiza...   \n",
       "\n",
       "                                             prev_q_tags  avg_ansrs_score  \\\n",
       "0      [consulting, resume, consulting, resume, consu...              5.0   \n",
       "1                                                    NaN              NaN   \n",
       "2      [experience, healthcare, doctor, anesthesiolog...              1.0   \n",
       "3      [experience, healthcare, doctor, anesthesiolog...              0.0   \n",
       "4      [experience, healthcare, doctor, anesthesiolog...              3.0   \n",
       "...                                                  ...              ...   \n",
       "68186                                                NaN              NaN   \n",
       "68187                                                NaN              NaN   \n",
       "68188                                                NaN              NaN   \n",
       "68189                                                NaN              NaN   \n",
       "68190                                                NaN              NaN   \n",
       "\n",
       "       num_groups  num_schools  num_emails  answrs_emails_ratio  \n",
       "0             NaN          NaN         NaN                  NaN  \n",
       "1             NaN          NaN         NaN                  NaN  \n",
       "2             NaN          NaN        70.0             0.557143  \n",
       "3             NaN          NaN        70.0             0.557143  \n",
       "4             NaN          NaN        70.0             0.557143  \n",
       "...           ...          ...         ...                  ...  \n",
       "68186         NaN          NaN         NaN                  NaN  \n",
       "68187         NaN          NaN         NaN                  NaN  \n",
       "68188         NaN          NaN         NaN                  NaN  \n",
       "68189         NaN          NaN         NaN                  NaN  \n",
       "68190         NaN          NaN         NaN                  NaN  \n",
       "\n",
       "[68191 rows x 11 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final data: \n",
    "professionals_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
